import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from UNet_network import UNet
from function import data_load, mini_batch, index_to_color
from torchvision import models
import time
from tqdm import tqdm
import os
import cv2

try_name = '10.27.interpolate'

# data load
print('Datasets loading...')
path = r'D:\es\DATASET\VOCdevkit\VOC2012'

while 1:
    choice = input('from (1) scratch or (2) npy: ')
    if choice == '1':
        train_names, test_names, train, test, train_gts, test_gts = data_load(path)
        np.save(r'D:\kse\npy\train.npy', train)
        np.save(r'D:\kse\npy\test.npy', test)
        np.save(r'D:\kse\npy\train_gts.npy', train_gts)
        np.save(r'D:\kse\npy\test_gts.npy', test_gts)
        print('data save finished')
        break
    elif choice == '2':
        train = np.load(r'D:\kse\npy\train.npy')
        test = np.load(r'D:\kse\npy\test.npy')
        train_gts = np.load(r'D:\kse\npy\train_gts.npy')
        test_gts = np.load(r'D:\kse\npy\test_gts.npy')
        train_names = (open(os.path.join(path, 'ImageSets/Segmentation/train.txt'), 'r')).readlines()
        test_names = (open(os.path.join(path, 'ImageSets/Segmentation/val.txt'), 'r')).readlines()
        print('Datasets loading completed')
        break
    else:
        print('choose 1 or 2')

VOC_CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car",
               "cat", "chair", "cow", "diningtable", "dog", "horse", "motorbike", "person",
               "potted plant", "sheep", "sofa", "train", "tv/monitor"]

VOC_COLORMAP = np.array([[0, 0, 0], [0, 0, 128], [0, 128, 0], [0, 128, 128], [128, 0, 0], [128, 0, 128],
                [128, 128, 0], [128, 128, 128], [0, 0, 64], [0, 0, 192], [0, 128, 64], [0, 128, 192],
                [128, 0, 64], [128, 0, 192], [128, 128, 64], [128, 128, 192], [0, 64, 0], [0, 64, 128],
                [0, 192, 0], [0, 192, 128], [128, 64, 0]])

train_n, test_n = len(train), len(test)
class_num = len(VOC_CLASSES)

batch_size = 32
lr = 0.001
iter = 200000
start = 1

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet().to(device)
# model_load = 50000
# model.load_state_dict(torch.load(f'model/{try_name}_{model_load}.pt'))
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-8)
start_time = time.time()

print('train start')
# train # tensorbord에 결과 저장 가능
for i in range(start, iter + 1):
    if i == 25000:
        optimizer.param_groups[0]['lr'] = 0.0005
    elif i == 50000:
        optimizer.param_groups[0]['lr'] = 0.0001
    elif i == 75000:
        optimizer.param_groups[0]['lr'] = 0.00005
    elif i == 100000:
        optimizer.param_groups[0]['lr'] = 0.00001
    elif i == 150000:
        optimizer.param_groups[0]['lr'] = 0.000005
    elif i == 175000:
        optimizer.param_groups[0]['lr'] = 0.000001

    f1 = open(f'UNet loss_{try_name}.txt', 'a+')
    f2 = open(f'UNet accuracy_{try_name}.txt', 'a+')
    model.train()

    optimizer.zero_grad()
    batch_img, batch_gts = mini_batch(train_n, batch_size, train, train_gts)
    batch_img, batch_gts = torch.from_numpy(batch_img), torch.from_numpy(batch_gts).type(torch.LongTensor)
    batch_img, batch_gts = batch_img.to(device), batch_gts.to(device)

    output = model(batch_img)
    loss = criterion(output, batch_gts)
    loss.backward()
    optimizer.step()

    if i % 500 == 0:
        model.eval()
        with torch.no_grad():
            batch_img, batch_gts = mini_batch(test_n, batch_size, test, test_gts)
            batch_img, batch_gts = torch.from_numpy(batch_img).to(device), torch.from_numpy(batch_gts).type(torch.LongTensor).to(device)
            output = model(batch_img)
            test_loss = criterion(output, batch_gts)
        f1.write(f'{i}\t{loss:.6f}\t{test_loss:.6f}\t{optimizer.param_groups[0]["lr"]:.10f}\n')
        print(f'{i}\t{loss:.6f}\t{test_loss:.6f}\t{optimizer.param_groups[0]["lr"]:.10f}')


    # test and save model
    if i % 10000 == 0:
        torch.save(model.state_dict(), f'model/{try_name}_{i}.pt')
        model.eval()

        #initialize
        total_mIoU = 0
        total_c_m = np.zeros(shape=(21, 21), dtype=np.uint32)

        with torch.no_grad():
            for j in tqdm(range(test_n), desc='testing...'):
                test_img = test[j:j+1, :, :, :] / 255.0 * 2.0 - 1.0
                test_img = np.transpose(test_img, (0, 3, 1, 2))
                test_img = torch.from_numpy(test_img.astype(np.float32)).to(device)

                test_output = model(test_img)
                test_output = np.squeeze(test_output.cpu().numpy())
                test_output = np.transpose(test_output, (1, 2, 0))

                # class만 저장
                test_gt = test_gts[j:j+1, :, :]
                pred = np.argmax(test_output, axis=-1)

                # accuracy
                pixel_accuracy, count = 0, 0
                confusion_mtx = np.zeros(shape=(21, 21), dtype=np.uint32)       # (pred, gt)
                comparison = np.zeros(shape=(2, 256*256), dtype=np.uint8)
                comparison[0], comparison[1] = pred.reshape(-1), test_gt.reshape(-1)
                comparison = np.transpose(comparison, (1, 0))
                for p in range(21):
                    for q in range(21):
                        count = np.sum(np.all(comparison == (p, q), axis=1))
                        confusion_mtx[p, q] = count
                        total_c_m[p, q] += count
                        if p == q:
                            pixel_accuracy += count
                pixel_accuracy = pixel_accuracy / (256 * 256)

                count, IoU_sum = 0, 0.
                for k in range(21):
                    union = sum(confusion_mtx[k, :]) + sum(confusion_mtx[:, k]) - confusion_mtx[k, k]
                    if union != 0:
                        count += 1
                        IoU_sum += (confusion_mtx[k, k] / union)  # 각각의 class에 대한 IoU
                mIoU = IoU_sum / count

                # saving predicted image
                result_img = index_to_color(pred)    # index를 rgb로 변환하여 result image 생성, (128, 128, 3)
                os.makedirs(f'D:/kse/output/{try_name}_{i}', exist_ok=True)
                cv2.imwrite(f'D:/kse/output/{try_name}_{i}/{test_names[j]}({pixel_accuracy:.4},{mIoU:.4}).jpg', result_img)

        total_pixel_accuracy = 0

        for j in range(21):
            total_img_union = sum(total_c_m[j, :]) + sum(total_c_m[:, j]) - total_c_m[j, j]
            total_mIoU += (total_c_m[j, j] / total_img_union)
            total_pixel_accuracy += total_c_m[j, j]

        total_pixel_accuracy /= (256 * 256 * test_n)
        total_mIoU /= 21
        f2.write(f'{i}\t{total_pixel_accuracy:.4}\t{total_mIoU:.4}\n')

        test_time = time.time()
        elapsed_time = (test_time - start_time) / 3600
        learning_rate = optimizer.param_groups[0]['lr']
        print(f'step: {i}\t||  pixel accuracy: {total_pixel_accuracy:.4f},\tmIoU: {total_mIoU:.4f},\tlr: {learning_rate:.6f},\ttime: {elapsed_time:.1f}')

    f1.close()
    f2.close()
